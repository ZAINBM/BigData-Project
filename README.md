# BigData-Project
🔹Overview 
* This project builds a scalable big data analytics pipeline to process 930,000+ housing records from Austin, uncovering patterns in housing affordability and infrastructure disparities across neighborhoods. The insights aim to support equitable urban development and align with UN Sustainable Development Goal 11 (Sustainable Cities and Communities). 

🔹Key Contributions
* ⚡ Big Data Pipeline: Designed with Hadoop, HDFS, and MapReduce for large-scale housing data processing.
* 🔍 Feature Engineering: Used Python, Pandas, NumPy with transformations, outlier filtering, and derived metrics (price/sqft, property age) to improve interpretability.
* 🔄 Parallel Processing: Implemented 5 parallel MapReduce jobs (via Hadoop Streaming + Python) to extract city-wise, property-type, structural, and temporal trends.
* 📊 Urban Insights: Enabled data-driven analysis of affordability gaps, neighborhood disparities, and housing infrastructure trends.

🔹 Tech Stack
* Big Data Tools: Hadoop, HDFS, MapReduce (Hadoop Streaming with Python)
* Languages & Libraries: Python, Pandas, NumPy
* Data Size: 930,000+ housing records

🔹 Value
* Provides predictive insights for real estate markets.
* Demonstrates scalable data engineering and feature engineering for machine learning.
* Supports sustainable urban planning with actionable, data-driven evidence.
